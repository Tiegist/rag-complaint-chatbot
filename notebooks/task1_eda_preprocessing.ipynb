{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 1: Exploratory Data Analysis and Data Preprocessing\n",
        "\n",
        "This notebook performs EDA and preprocessing on the CFPB complaint dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "\n",
        "# Add src to path\n",
        "sys.path.append('../src')\n",
        "from data_processing import ComplaintDataProcessor\n",
        "\n",
        "# Set style\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Data\n",
        "\n",
        "First, we'll load the CFPB complaint dataset. Make sure the file is placed in `data/raw/complaints.csv`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize processor\n",
        "data_path = '../data/raw/complaints.csv'\n",
        "processor = ComplaintDataProcessor(data_path)\n",
        "\n",
        "# Load data\n",
        "df = processor.load_data()\n",
        "print(f\"\\nDataset shape: {df.shape}\")\n",
        "print(f\"Columns: {df.columns.tolist()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exploratory Data Analysis\n",
        "\n",
        "Let's perform comprehensive EDA to understand the data structure, distributions, and quality.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Perform EDA\n",
        "eda_stats = processor.perform_eda()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Filter Data\n",
        "\n",
        "Filter the dataset to include only the target products and non-empty narratives.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filter data\n",
        "filtered_df = processor.filter_data()\n",
        "print(f\"\\nFiltered dataset shape: {filtered_df.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preprocess Data\n",
        "\n",
        "Clean the text narratives to improve embedding quality.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preprocess data\n",
        "preprocessed_df = processor.preprocess_data()\n",
        "print(f\"\\nPreprocessed dataset shape: {preprocessed_df.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Cleaned Data\n",
        "\n",
        "Save the cleaned and filtered dataset for use in Task 2.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save cleaned data\n",
        "processor.save_cleaned_data('../data/processed/filtered_complaints.csv')\n",
        "print(\"\\n✅ Task 1 Complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display final summary statistics\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FINAL SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nTotal records processed: {eda_stats['total_records']:,}\")\n",
        "print(f\"Records after filtering: {len(filtered_df):,}\")\n",
        "print(f\"Records after preprocessing: {len(preprocessed_df):,}\")\n",
        "if eda_stats.get('mean_word_count'):\n",
        "    print(f\"Mean narrative length: {eda_stats['mean_word_count']:.2f} words\")\n",
        "    print(f\"Median narrative length: {eda_stats['median_word_count']:.2f} words\")\n",
        "if 'Product' in preprocessed_df.columns:\n",
        "    print(\"\\nProduct distribution:\")\n",
        "    product_dist = preprocessed_df['Product'].value_counts()\n",
        "    for product, count in product_dist.items():\n",
        "        print(f\"  - {product}: {count:,} ({count/len(preprocessed_df)*100:.1f}%)\")\n",
        "print(\"\\n\" + \"=\"*60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save cleaned data\n",
        "processor.save_cleaned_data('../data/processed/filtered_complaints.csv')\n",
        "print(\"\\n✅ Task 1 Complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "**Key Findings:**\n",
        "- Total records processed: [Fill in from EDA]\n",
        "- Records after filtering: [Fill in]\n",
        "- Records after preprocessing: [Fill in]\n",
        "- Mean narrative length: [Fill in] words\n",
        "- Product distribution: [Fill in]\n",
        "\n",
        "**Next Steps:**\n",
        "- Proceed to Task 2: Text Chunking and Embedding\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
